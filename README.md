Applied Regression Analysis project

- This is the final project I did in the course Applied Regression Analysis in my first year in the M.S. Biostatistics program in 4/2016. 
 - I used the 2014 Behavioral Risk Factor Surveillance System data to find risk factors for poor mental health. I used SAS to build a statistical model and wrote a formal report on the results styled as a statistical manuscript. In my final model, hours worked, hours slept, age group, education level, smoking frequency, number of days in a month bad physical health, and an interaction between hours slept and number of days in a month bad physical health were found to be significant. However, since my final model not meet the assumptions of linear regression the results were actually invalid.

Springboard project 1

- This is the first project I did for Springboard's Data Science Career Track from 2/2018 to 3/2018.
 - I used video game sales with ratings data from Kaggle to find the best set of predictors for Global Sales and compare predictive power from a statistical model to machine learning models. I cleaned 16719 rows of data and used NumPy, Pandas, Matplotlib, Seaborn, and Plotnine to conduct an exploratory data analysis. I split the data into 80% train and 20% test and used statsmodels to build the best multiple linear regression model I could. I used sci-kit learn to build many machine learning models including linear, ridge, support vector machine, random forest, and extreme gradient boosting regressor models. In the end, I found that all the machine learning models performed better than the statistical model with random forest regression with the lowest MSE. My results were not completely conclusive because I wasn't able to validate the statistical model.

Udacity Project 1

- The first project I did with Udacity in 10/2017
  - I extracted weather data from the Udacity database using SQL with the goal of finding the 7-day moving average for Columbus, Berlin, Belgrade, Tunis, and globally. I imported the data into R using  readr and used dyplyr, ggplot2, Hmisc to answer the question and additional analysis such as building a simple linear regression statistical model and then wrote a report on the results. I found that Columbus is hotter on average compared to the global average.
  
Udacity Project 3

- The third project I did with Udacity in 12/2017
  - I used the TMDB movie data to discover which genres when paired with the genre that contributes the most profit drives the average rating upward.  I cleaned 11000 rows of data and then used NumPy and Pandas to answer that question. I also used matplotlib and plotnine to visualize the data. I created a report using jupyter notebook and found that Adventure contributes the most to profit. Animation, drama, family, fantasy, mystery, science fiction, war, and western are the genres when paired with Adventure drives the Adventure genre upward.   

Udacity Project 5

- The fifth project I did with Udacity in 3/2018
  - I used a red wine quality dataset from Udacity to determine what chemical properties influence the quality of red wines. I performed exploratory data analysis in R while documenting my exploration and analysis in a RMD file. I utilized univariate, bivariate, and multivariate means to find patterns in the data. With bivariate analysis, I found that higher quality wines are associated with higher fixed acidity, lower volatile acidity, higher citric acid, less chlorides, higher alcohol content, higher sulphates, and lower density. With multivariate analysis, I found that higher quality wine on average exhibit a total sulfur dioxide of between 15 to 50 depending on the ratio of free sulfur dioxide to total sulfur dioxide which should be between 0.15 and 0.75 and that after adjusting for alcohol content, higher quality wines tend to have a low amount of residual sugar compared to lower quality wines.
 
 Udacity Project 6
 
 - The sixth project I did with Udacity in 4/2018
   - I gathered three WeRateDogs twitter datasets including querying the Twitter API using Tweepy. I assessed data quality issues in a jupyter notebook and then cleaned the datasets before merging them into one dataset. I discovered a few insights about the wrangled data which includes that the Golden Retriever was the most frequently predicted dog.
